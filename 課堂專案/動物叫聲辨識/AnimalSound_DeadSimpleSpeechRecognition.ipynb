{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CBB9D1vBbCe",
        "outputId": "534fa357-1e0c-454d-980b-37c16255cb32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Animal-Soundprepros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afNpCU50GvJd",
        "outputId": "3a6cd6a3-a729-476d-e6be-c2cc1f3584f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Animal-Soundprepros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def stats(matrix):\n",
        "    if matrix.size == 0:\n",
        "        return np.zeros(5)\n",
        "    return np.array([\n",
        "        np.mean(matrix),\n",
        "        np.std(matrix),\n",
        "        np.max(matrix),\n",
        "        np.min(matrix),\n",
        "        np.median(matrix)\n",
        "    ])\n",
        "\n",
        "def librosa_featurize(filename):\n",
        "    y, sr = librosa.load(filename)\n",
        "    y = y[::3]\n",
        "\n",
        "    S = np.abs(librosa.stft(y))\n",
        "    C = np.abs(librosa.cqt(y, sr=sr))\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    poly_features = librosa.feature.poly_features(S=S, sr=sr)\n",
        "    chroma_cens = librosa.feature.chroma_cens(C=C, sr=sr)\n",
        "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    tempogram = librosa.feature.tempogram(y=y, sr=sr)\n",
        "\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)[0]\n",
        "    spectral_flatness = librosa.feature.spectral_flatness(y=y)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
        "\n",
        "    onset = librosa.onset.onset_detect(y=y, sr=sr)\n",
        "    if onset.size == 0:\n",
        "        onset_stats = np.zeros(5)\n",
        "    else:\n",
        "        onset_stats = stats(onset)\n",
        "\n",
        "    onset_features = np.concatenate([\n",
        "        np.array([len(onset)]),\n",
        "        onset_stats,\n",
        "        np.array([librosa.beat.tempo(y=y, sr=sr)[0]]),\n",
        "        stats(librosa.onset.onset_strength(y=y, sr=sr))\n",
        "    ])\n",
        "\n",
        "    rhythm_features = np.concatenate([stats(tempogram[i]) for i in range(min(13, tempogram.shape[0]))])\n",
        "\n",
        "    spectral_features = np.concatenate([\n",
        "        *[stats(mfcc[i]) for i in range(min(13, mfcc.shape[0]))],\n",
        "        stats(poly_features[0]),\n",
        "        stats(poly_features[1]),\n",
        "        stats(spectral_centroid),\n",
        "        stats(spectral_bandwidth),\n",
        "        stats(spectral_contrast),\n",
        "        stats(spectral_flatness),\n",
        "        stats(spectral_rolloff)\n",
        "    ])\n",
        "\n",
        "    power_features = np.concatenate([\n",
        "        stats(librosa.feature.zero_crossing_rate(y=y)[0]),\n",
        "        stats(librosa.feature.rms(y=y)[0])\n",
        "    ])\n",
        "\n",
        "    features = np.concatenate([\n",
        "        onset_features,\n",
        "        rhythm_features,\n",
        "        spectral_features,\n",
        "        power_features\n",
        "    ])\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "SaXja_H-Gs7O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Animal-Soundprepros\"\n",
        "\n",
        "\n",
        "# Input: Folder Path\n",
        "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
        "def get_labels(path=DATA_PATH):\n",
        "    labels = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices, to_categorical(label_indices)\n",
        "\n",
        "\n",
        "# Handy function to convert wav2mfcc\n",
        "def wav2mfcc(file_path, max_len=13):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=wave, sr=sr)\n",
        "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
        "    if (max_len > mfcc.shape[1]):\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    # Else cutoff the remaining parts\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "\n",
        "def save_mfcc_data_to_array(path=DATA_PATH, max_len=13):\n",
        "    labels, _, _ = get_labels(path)\n",
        "\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        mfcc_vectors = []\n",
        "\n",
        "        wavfiles = [os.path.join(path, label, wavfile) for wavfile in os.listdir(os.path.join(path, label))]\n",
        "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
        "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
        "            mfcc_vectors.append(mfcc)\n",
        "        np.save(os.path.join(path, label + '.npy'), mfcc_vectors)\n",
        "\n",
        "\n",
        "def save_feature_data_to_array(path=DATA_PATH):\n",
        "    labels, _, _ = get_labels(path)\n",
        "\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        feature_vectors = []\n",
        "\n",
        "        wavfiles = [os.path.join(path, label, wavfile) for wavfile in os.listdir(os.path.join(path, label)) if wavfile.endswith('.wav')]\n",
        "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
        "            feature = librosa_featurize(wavfile)\n",
        "            feature_vectors.append(feature)\n",
        "        np.save(label + '.npy', feature_vectors)\n",
        "\n",
        "\n",
        "def get_train_test(split_ratio=0.8, random_state=42):\n",
        "    # Get available labels\n",
        "    labels, indices, _ = get_labels(DATA_PATH)\n",
        "\n",
        "    # Getting first arrays\n",
        "    X = np.load(os.path.join(DATA_PATH, labels[0] + '.npy'))\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load(os.path.join(DATA_PATH, label + '.npy'))\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "\n",
        "def prepare_dataset(path=DATA_PATH):\n",
        "    labels, _, _ = get_labels(path)\n",
        "    data = {}\n",
        "    for label in labels:\n",
        "        data[label] = {}\n",
        "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "\n",
        "        vectors = []\n",
        "\n",
        "        for wavfile in data[label]['path']:\n",
        "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
        "            # Downsampling\n",
        "            wave = wave[::3]\n",
        "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
        "            vectors.append(mfcc)\n",
        "\n",
        "        data[label]['mfcc'] = vectors\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_dataset(path=DATA_PATH):\n",
        "    data = prepare_dataset(path)\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for key in data:\n",
        "        for mfcc in data[key]['mfcc']:\n",
        "            dataset.append((key, mfcc))\n",
        "\n",
        "    return dataset[:100]\n"
      ],
      "metadata": {
        "id": "XEW0V8XDGox5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to array file first\n",
        "save_feature_data_to_array()\n",
        "\n",
        "# # Loading train set and test set\n",
        "X_train, X_test, y_train, y_test = get_train_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mGnqoLVGiPq",
        "outputId": "ac6ba8be-4742-4c51-f563-430dd8f9cc80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vectors of label - 'Aslan': 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]\n",
            "Saving vectors of label - 'Bear': 100%|██████████| 50/50 [00:11<00:00,  4.29it/s]\n",
            "Saving vectors of label - 'Cat': 100%|██████████| 50/50 [00:11<00:00,  4.50it/s]\n",
            "Saving vectors of label - 'Chicken': 100%|██████████| 50/50 [00:12<00:00,  4.06it/s]\n",
            "Saving vectors of label - 'Cow': 100%|██████████| 50/50 [00:10<00:00,  4.84it/s]\n",
            "Saving vectors of label - 'Dog': 100%|██████████| 50/50 [00:09<00:00,  5.06it/s]\n",
            "Saving vectors of label - 'Dolphin': 100%|██████████| 50/50 [00:11<00:00,  4.40it/s]\n",
            "Saving vectors of label - 'Donkey': 100%|██████████| 50/50 [00:12<00:00,  3.97it/s]\n",
            "Saving vectors of label - 'Elephant': 100%|██████████| 50/50 [00:12<00:00,  4.05it/s]\n",
            "Saving vectors of label - 'Frog': 100%|██████████| 50/50 [00:11<00:00,  4.46it/s]\n",
            "Saving vectors of label - 'Horse': 100%|██████████| 50/50 [00:09<00:00,  5.25it/s]\n",
            "Saving vectors of label - 'Monkey': 100%|██████████| 50/50 [00:12<00:00,  4.00it/s]\n",
            "Saving vectors of label - 'Sheep': 100%|██████████| 50/50 [00:11<00:00,  4.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Random Forest Classifier Evaluation\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-8QLVwlMFOe",
        "outputId": "ce80001e-c15c-4b1b-cf7d-32e8e1cf34a0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier Evaluation\n",
            "Accuracy: 74.62%\n",
            "Confusion Matrix:\n",
            "[[ 9  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1 13  0  0  1  0  0  0  0  0  1  0  0]\n",
            " [ 0  0  8  0  1  0  1  0  1  0  0  0  0]\n",
            " [ 0  0  0  5  1  1  0  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  8  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  1  0  0  7  0  1  0  2  0  1]\n",
            " [ 0  0  0  0  0  0  0  8  0  0  0  0  0]\n",
            " [ 1  0  0  1  0  0  0  0  7  1  0  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  7  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  6  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  4  1]\n",
            " [ 0  1  0  0  0  1  1  0  0  0  1  3  4]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.90      0.86        10\n",
            "         1.0       0.81      0.81      0.81        16\n",
            "         2.0       0.89      0.73      0.80        11\n",
            "         3.0       0.62      0.62      0.62         8\n",
            "         4.0       0.79      1.00      0.88        11\n",
            "         5.0       0.80      0.89      0.84         9\n",
            "         6.0       0.78      0.54      0.64        13\n",
            "         7.0       1.00      1.00      1.00         8\n",
            "         8.0       0.64      0.64      0.64        11\n",
            "         9.0       0.88      1.00      0.93         7\n",
            "        10.0       0.60      0.67      0.63         9\n",
            "        11.0       0.44      0.67      0.53         6\n",
            "        12.0       0.57      0.36      0.44        11\n",
            "\n",
            "    accuracy                           0.75       130\n",
            "   macro avg       0.74      0.76      0.74       130\n",
            "weighted avg       0.75      0.75      0.74       130\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Second dimension of the feature is dim2\n",
        "feature_dim_2 = 13\n",
        "\n",
        "# Save data to array file first\n",
        "save_mfcc_data_to_array(max_len=feature_dim_2)\n",
        "\n",
        "# # Loading train set and test set\n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "# # Feature dimension\n",
        "feature_dim_1 = 20\n",
        "channel = 1\n",
        "epochs = 50\n",
        "batch_size = 64  #原為100\n",
        "verbose = 1\n",
        "num_classes = 13\n",
        "\n",
        "# Reshaping to perform 2D convolution\n",
        "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C60MSSfuBkUd",
        "outputId": "8002ed3e-c8c8-4a0f-b7ed-6eabaaf8a654"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vectors of label - 'Aslan': 100%|██████████| 50/50 [00:00<00:00, 80.77it/s]\n",
            "Saving vectors of label - 'Bear': 100%|██████████| 50/50 [00:00<00:00, 74.71it/s]\n",
            "Saving vectors of label - 'Cat': 100%|██████████| 50/50 [00:01<00:00, 28.80it/s]\n",
            "Saving vectors of label - 'Chicken': 100%|██████████| 50/50 [00:01<00:00, 35.08it/s]\n",
            "Saving vectors of label - 'Cow': 100%|██████████| 50/50 [00:00<00:00, 102.38it/s]\n",
            "Saving vectors of label - 'Dog': 100%|██████████| 50/50 [00:00<00:00, 128.23it/s]\n",
            "Saving vectors of label - 'Dolphin': 100%|██████████| 50/50 [00:00<00:00, 132.12it/s]\n",
            "Saving vectors of label - 'Donkey': 100%|██████████| 50/50 [00:00<00:00, 96.67it/s]\n",
            "Saving vectors of label - 'Elephant': 100%|██████████| 50/50 [00:00<00:00, 90.99it/s]\n",
            "Saving vectors of label - 'Frog': 100%|██████████| 50/50 [00:00<00:00, 88.93it/s]\n",
            "Saving vectors of label - 'Horse': 100%|██████████| 50/50 [00:00<00:00, 120.48it/s]\n",
            "Saving vectors of label - 'Monkey': 100%|██████████| 50/50 [00:00<00:00, 71.91it/s]\n",
            "Saving vectors of label - 'Sheep': 100%|██████████| 50/50 [00:00<00:00, 99.75it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cl3p5xOMBbCi"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
        "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Predicts one sample\n",
        "def predict(filepath, model):\n",
        "    sample = wav2mfcc(filepath)\n",
        "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
        "    return get_labels()[0][\n",
        "            np.argmax(model.predict(sample_reshaped))\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zQgD0TpBbCj"
      },
      "source": [
        "# Building The Model Then Training it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axi-EPo9BbCl",
        "outputId": "28c0ee5b-06ff-47d0-c871-9efe6de46d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.0757 - loss: 4.0900 - val_accuracy: 0.1385 - val_loss: 2.5440\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1501 - loss: 2.4831 - val_accuracy: 0.2769 - val_loss: 2.3036\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2651 - loss: 2.2270 - val_accuracy: 0.2615 - val_loss: 2.1638\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4086 - loss: 1.9190 - val_accuracy: 0.3615 - val_loss: 1.9385\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4528 - loss: 1.7478 - val_accuracy: 0.4615 - val_loss: 1.7529\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5323 - loss: 1.4545 - val_accuracy: 0.4692 - val_loss: 1.6731\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6415 - loss: 1.2215 - val_accuracy: 0.4769 - val_loss: 1.7609\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6561 - loss: 1.0489 - val_accuracy: 0.5154 - val_loss: 1.6764\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7207 - loss: 0.8789 - val_accuracy: 0.5385 - val_loss: 1.5233\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7938 - loss: 0.7148 - val_accuracy: 0.5308 - val_loss: 1.4942\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8284 - loss: 0.5969 - val_accuracy: 0.5385 - val_loss: 1.4983\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8999 - loss: 0.4082 - val_accuracy: 0.5846 - val_loss: 1.5648\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8835 - loss: 0.3495 - val_accuracy: 0.5538 - val_loss: 1.7125\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9140 - loss: 0.3151 - val_accuracy: 0.5769 - val_loss: 1.6387\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8962 - loss: 0.3236 - val_accuracy: 0.5308 - val_loss: 1.9381\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9408 - loss: 0.2440 - val_accuracy: 0.5692 - val_loss: 1.5288\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9577 - loss: 0.2006 - val_accuracy: 0.5692 - val_loss: 1.9947\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9728 - loss: 0.1307 - val_accuracy: 0.6231 - val_loss: 1.7952\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0933 - val_accuracy: 0.6000 - val_loss: 1.8146\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0739 - val_accuracy: 0.6077 - val_loss: 2.0837\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.0480 - val_accuracy: 0.6077 - val_loss: 1.8764\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0402 - val_accuracy: 0.6077 - val_loss: 1.9940\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0317 - val_accuracy: 0.6000 - val_loss: 2.0098\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0237 - val_accuracy: 0.5923 - val_loss: 2.0844\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0157 - val_accuracy: 0.6077 - val_loss: 2.0990\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 0.0153 - val_accuracy: 0.5923 - val_loss: 2.2327\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0136 - val_accuracy: 0.6154 - val_loss: 2.2382\n",
            "Epoch 28/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0093 - val_accuracy: 0.6154 - val_loss: 2.2261\n",
            "Epoch 29/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0127 - val_accuracy: 0.6231 - val_loss: 2.2669\n",
            "Epoch 30/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0133 - val_accuracy: 0.6154 - val_loss: 2.3009\n",
            "Epoch 31/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.6154 - val_loss: 2.3464\n",
            "Epoch 32/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.6000 - val_loss: 2.3044\n",
            "Epoch 33/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.0061 - val_accuracy: 0.6154 - val_loss: 2.3311\n",
            "Epoch 34/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0089 - val_accuracy: 0.6231 - val_loss: 2.3550\n",
            "Epoch 35/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.6077 - val_loss: 2.3996\n",
            "Epoch 36/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.6000 - val_loss: 2.3770\n",
            "Epoch 37/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.6154 - val_loss: 2.4269\n",
            "Epoch 38/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9977 - loss: 0.0055 - val_accuracy: 0.6077 - val_loss: 2.4290\n",
            "Epoch 39/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.6154 - val_loss: 2.4668\n",
            "Epoch 40/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.6077 - val_loss: 2.4747\n",
            "Epoch 41/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 0.6077 - val_loss: 2.5016\n",
            "Epoch 42/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0072 - val_accuracy: 0.6231 - val_loss: 2.5311\n",
            "Epoch 43/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.6154 - val_loss: 2.4858\n",
            "Epoch 44/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 0.0080 - val_accuracy: 0.6077 - val_loss: 2.4772\n",
            "Epoch 45/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9943 - loss: 0.0107 - val_accuracy: 0.6077 - val_loss: 2.5155\n",
            "Epoch 46/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.0092 - val_accuracy: 0.6231 - val_loss: 2.5104\n",
            "Epoch 47/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.6231 - val_loss: 2.5612\n",
            "Epoch 48/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0085 - val_accuracy: 0.6154 - val_loss: 2.5550\n",
            "Epoch 49/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0055 - val_accuracy: 0.6077 - val_loss: 2.5460\n",
            "Epoch 50/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.6154 - val_loss: 2.5695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e22e3629910>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSqmizNvBbCm"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFU5Hw1oBbCn",
        "outputId": "f74b6a74-2cd4-4dd9-f3af-3af04a89aacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "Dolphin\n"
          ]
        }
      ],
      "source": [
        "print(predict('/content/drive/MyDrive/Animal-Soundprepros/Dolphin/Dolphin_37.wav', model=model))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PAFb8JrMGI4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}